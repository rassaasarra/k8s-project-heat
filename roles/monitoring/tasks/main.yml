# roles/monitoring/tasks/main.yml

- name: Stop if not master
  meta: end_play
  when: k8s_role != "master"

- name: Define kubeconfig path
  set_fact:
    kcfg: /etc/kubernetes/admin.conf

- name: Wait for Kubernetes API to be reachable
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl version --request-timeout=5s >/dev/null
  args:
    executable: /bin/bash
  register: api_ok
  retries: 30
  delay: 5
  until: api_ok.rc == 0
  changed_when: false

- name: Install Helm if missing
  become: yes
  shell: |
    set -e
    if ! command -v helm >/dev/null 2>&1; then
      curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    fi
    helm version --short >/dev/null
  args:
    executable: /bin/bash
  changed_when: false

- name: Add Helm repos and update
  become: yes
  shell: |
    set -e
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts >/dev/null 2>&1 || true
    helm repo update >/dev/null
  args:
    executable: /bin/bash
  changed_when: false

- name: Ensure monitoring namespace exists
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl get ns monitoring >/dev/null 2>&1 || kubectl create ns monitoring
  args:
    executable: /bin/bash
  changed_when: false

# ---- Values file (NodePort) ----
# - On fixe NodePort=30000 si dispo, sinon Kubernetes refusera et Helm Ã©chouera.
# - On nâ€™impose PAS adminPassword="admin" (secret auto-gÃ©nÃ©rÃ©).
- name: Create values file for kube-prometheus-stack (Grafana NodePort)
  become: yes
  copy:
    dest: /tmp/kube-prometheus-stack-values.yaml
    mode: "0644"
    content: |
      grafana:
        service:
          type: NodePort
          nodePort: 30000
          port: 80
          targetPort: 3000

      # (Optionnel) petits clusters / lab : dÃ©sactiver certains scrapes si pas prÃ©sents
      kubeEtcd:
        enabled: false
      kubeControllerManager:
        enabled: false
      kubeScheduler:
        enabled: false

- name: Deploy/Upgrade kube-prometheus-stack (first attempt)
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
      --namespace monitoring \
      --create-namespace \
      --values /tmp/kube-prometheus-stack-values.yaml \
      --wait \
      --timeout 15m
  args:
    executable: /bin/bash
  register: helm_out
  retries: 2
  delay: 20
  until: helm_out.rc == 0
  failed_when: false

# Si NodePort 30000 est dÃ©jÃ  pris, Helm peut Ã©chouer. On retente sans nodePort fixe.
- name: Fallback values without fixed NodePort if install failed
  become: yes
  when: helm_out.rc != 0
  copy:
    dest: /tmp/kube-prometheus-stack-values-fallback.yaml
    mode: "0644"
    content: |
      grafana:
        service:
          type: NodePort
          port: 80
          targetPort: 3000

      kubeEtcd:
        enabled: false
      kubeControllerManager:
        enabled: false
      kubeScheduler:
        enabled: false

- name: Deploy/Upgrade kube-prometheus-stack (fallback)
  become: yes
  when: helm_out.rc != 0
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
      --namespace monitoring \
      --create-namespace \
      --values /tmp/kube-prometheus-stack-values-fallback.yaml \
      --wait \
      --timeout 15m
  args:
    executable: /bin/bash
  register: helm_out2
  retries: 2
  delay: 30
  until: helm_out2.rc == 0

- name: Wait for Prometheus Operator deployment to be available
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl -n monitoring wait --for=condition=Available deploy/prometheus-kube-prometheus-operator --timeout=600s
  args:
    executable: /bin/bash
  changed_when: false

- name: Wait for Grafana pods to be Ready
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl -n monitoring wait --for=condition=Ready pod -l app.kubernetes.io/name=grafana --timeout=600s
  args:
    executable: /bin/bash
  changed_when: false

- name: Wait for Grafana endpoints to exist (service wired)
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    test -n "$(kubectl -n monitoring get endpoints prometheus-grafana -o jsonpath='{.subsets[0].addresses[0].ip}' 2>/dev/null || true)"
  args:
    executable: /bin/bash
  register: ep_ok
  retries: 30
  delay: 5
  until: ep_ok.rc == 0
  changed_when: false

- name: Get Grafana NodePort (actual)
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl -n monitoring get svc prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}'
  args:
    executable: /bin/bash
  register: grafana_nodeport
  changed_when: false

- name: Get master IP (best effort)
  set_fact:
    master_ip: "{{ ansible_default_ipv4.address | default('') }}"

- name: Fallback master IP from kubectl if empty
  become: yes
  when: master_ip | length == 0
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' | head -n1
  args:
    executable: /bin/bash
  register: master_ip_kubectl
  changed_when: false

- name: Normalize master ip fact
  set_fact:
    master_ip_final: >-
      {{ (master_ip | length > 0) | ternary(master_ip, master_ip_kubectl.stdout) }}

- name: Get Grafana admin password (secret)
  become: yes
  shell: |
    set -e
    export KUBECONFIG={{ kcfg }}
    kubectl -n monitoring get secret prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d
  args:
    executable: /bin/bash
  register: grafana_pass
  changed_when: false
  failed_when: false

# Test local (sur le master) â€” le plus fiable pour valider NodePort
- name: Local HTTP check (from master) to confirm Grafana answers on NodePort
  become: yes
  shell: |
    set -e
    curl -sS -I --max-time 5 http://127.0.0.1:{{ grafana_nodeport.stdout }}/login | head -n1
  args:
    executable: /bin/bash
  register: grafana_http_local
  changed_when: false
  failed_when: false

- name: Show final info
  debug:
    msg: |
      âœ… Monitoring installÃ© (kube-prometheus-stack).
      ğŸ” Grafana: admin / {{ grafana_pass.stdout | default('N/A') }}

      ğŸŒ AccÃ¨s NodePort (depuis le master):
        http://127.0.0.1:{{ grafana_nodeport.stdout }}/login
        Test local: {{ grafana_http_local.stdout | default('HTTP local check failed') }}

      ğŸŒ AccÃ¨s NodePort (rÃ©seau):
        http://{{ master_ip_final }}:{{ grafana_nodeport.stdout }}/login

      ğŸ§­ Si ton PC ne peut pas joindre {{ master_ip_final }} (VPN / routing):
        âœ… Solution universelle: port-forward
          kubectl -n monitoring port-forward svc/prometheus-grafana 3000:80 --address 0.0.0.0
          puis: http://127.0.0.1:3000

        âœ… Ou SSH tunnel (si SSH joignable):
          ssh -L 3000:127.0.0.1:{{ grafana_nodeport.stdout }} ubuntu@{{ master_ip_final }}
          puis: http://127.0.0.1:3000
